{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# imports\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('dark_background')\n",
    "\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "outputs": [],
   "source": [
    "root_folder = Path.cwd().parent.parent\n",
    "data_folder = Path(root_folder).joinpath('data', 'external')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "outputs": [],
   "source": [
    "from src.data.task_1_food_security.dataset import Dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "outputs": [],
   "source": [
    "ds = Dataset(root_folder=root_folder)\n",
    "\n",
    "ds.prepare_dataset_array()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "def create_new_model():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(126, input_shape=(36, 11)))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 126)               69552     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 127       \n",
      "=================================================================\n",
      "Total params: 69,679\n",
      "Trainable params: 69,679\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_new_model()\n",
    "model.summary()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "log_dir = \"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You are trying to load a weight file containing 3 layers into a model with 2 layers.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-383-8dd87c82582f>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     47\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     48\u001B[0m     \u001B[0;31m# LOAD BEST MODEL to evaluate the performance of the model\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 49\u001B[0;31m     \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload_weights\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf'saved_models/best_model{fold_var}.pkl'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     50\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     51\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/omdena_base/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001B[0m in \u001B[0;36mload_weights\u001B[0;34m(self, filepath, by_name, skip_mismatch)\u001B[0m\n\u001B[1;32m    232\u001B[0m         raise ValueError('Load weights is not yet supported with TPUStrategy '\n\u001B[1;32m    233\u001B[0m                          'with steps_per_run greater than 1.')\n\u001B[0;32m--> 234\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0msuper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mModel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload_weights\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfilepath\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mby_name\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mskip_mismatch\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    235\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    236\u001B[0m   \u001B[0;34m@\u001B[0m\u001B[0mtrackable\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mno_automatic_dependency_tracking\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/omdena_base/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\u001B[0m in \u001B[0;36mload_weights\u001B[0;34m(self, filepath, by_name, skip_mismatch)\u001B[0m\n\u001B[1;32m   1220\u001B[0m             f, self.layers, skip_mismatch=skip_mismatch)\n\u001B[1;32m   1221\u001B[0m       \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1222\u001B[0;31m         \u001B[0mhdf5_format\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload_weights_from_hdf5_group\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlayers\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1223\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1224\u001B[0m   \u001B[0;32mdef\u001B[0m \u001B[0m_updated_config\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/omdena_base/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py\u001B[0m in \u001B[0;36mload_weights_from_hdf5_group\u001B[0;34m(f, layers)\u001B[0m\n\u001B[1;32m    675\u001B[0m                      \u001B[0;34m'containing '\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlayer_names\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m+\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    676\u001B[0m                      \u001B[0;34m' layers into a model with '\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfiltered_layers\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m+\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 677\u001B[0;31m                      ' layers.')\n\u001B[0m\u001B[1;32m    678\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    679\u001B[0m   \u001B[0;31m# We batch weight value assignments in a single backend call\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: You are trying to load a weight file containing 3 layers into a model with 2 layers."
     ]
    }
   ],
   "source": [
    "VALIDATION_ACCURACY = []\n",
    "VALIDATION_LOSS = []\n",
    "\n",
    "save_dir = Path.cwd().joinpath('saved_models')\n",
    "fold_var = 1\n",
    "\n",
    "kf = KFold(n_splits = 5)\n",
    "history_dir = {}\n",
    "for train_index, val_index in kf.split(ds.X_train):\n",
    "    training_x = ds.X_train[train_index]\n",
    "    training_y = ds.y_train[train_index]\n",
    "    validation_x = ds.X_train[val_index]\n",
    "    validation_y = ds.y_train[val_index]\n",
    "\n",
    "    # CREATE NEW MODEL\n",
    "    model = create_new_model()\n",
    "\n",
    "    # COMPILE NEW MODEL\n",
    "    adam = Adam(lr=0.001)\n",
    "    model.compile(loss=tf.keras.losses.MeanSquaredError(),\n",
    "                  optimizer=adam,\n",
    "                  metrics=[tf.keras.losses.MeanSquaredError()])\n",
    "\n",
    "    # CREATE CALLBACKS\n",
    "    # chk = ModelCheckpoint(f'saved_models/best_model{fold_var}.pkl',\n",
    "    #                   monitor='mean_squared_error',\n",
    "    #                   save_best_only=True,\n",
    "    #                   mode='min',\n",
    "    #                   verbose=0)\n",
    "    #\n",
    "    # callbacks_list = [chk]\n",
    "    # There can be other callbacks, but just showing one because it involves the model name\n",
    "    # This saves the best model\n",
    "    # FIT THE MODEL\n",
    "\n",
    "    history = model.fit(training_x,\n",
    "                        training_y,\n",
    "                        epochs=100,\n",
    "                        batch_size=100,\n",
    "                        callbacks=[tensorboard_callback],\n",
    "                        validation_data=(validation_x,validation_y),\n",
    "                        verbose=0)\n",
    "\n",
    "    #PLOT HISTORY\n",
    "    #\t\t:\n",
    "    #\t\t:\n",
    "\n",
    "    # LOAD BEST MODEL to evaluate the performance of the model\n",
    "    model.load_weights(f'saved_models/best_model{fold_var}.pkl')\n",
    "\n",
    "\n",
    "\n",
    "    results = model.evaluate(validation_x, validation_y)\n",
    "    results = dict(zip(model.metrics_names,results))\n",
    "    history_dir[str(fold_var)] = history\n",
    "    VALIDATION_ACCURACY.append(results['mean_squared_error'])\n",
    "    VALIDATION_LOSS.append(results['loss'])\n",
    "    print(f\"Fold {fold_var}\")\n",
    "    print(results)\n",
    "    print(\"+++++++++++++\"*5)\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    fold_var += 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "outputs": [
    {
     "data": {
      "text/plain": "'sequential_2'"
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.name"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import imblearn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "sentinel_1 = pd.read_csv('Sentinel_training_farms_Tuned_s1.csv')\n",
    "sentinel_2 = pd.read_csv('Sentinel_training_farms_Tuned_s2.csv')\n",
    "\n",
    "sentinel_1['season'] = 1\n",
    "sentinel_2['season'] = 2\n",
    "\n",
    "data = sentinel_1.append(sentinel_2) # concat season1 and season2 data\n",
    "\n",
    "data.drop(['system:index', '.geo'], axis=1, inplace=True)\n",
    "\n",
    "y = data['CID']\n",
    "X = data.drop(['CID'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel(X,y):\n",
    "    \n",
    "    \"\"\" This function takes in an array of 18 numbers: bands, ndvi and \n",
    "    season. \n",
    "    output: an array of 9 numbers representing the probability of each\n",
    "    of the 9 crops.\"\"\"\n",
    "    \n",
    "    #Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=True, stratify=y, random_state=123)\n",
    "        \n",
    "    # instantiate model\n",
    "    model = RandomForestClassifier(n_estimators=250)\n",
    "    \n",
    "    # Modeling code in a pipeline\n",
    "    my_pipeline = Pipeline(steps=[('model', model)])\n",
    "\n",
    "    \n",
    "    # Scaling training data ONLY:\n",
    "    smt = SMOTE(random_state = 123)\n",
    "    X_train_smote, y_train_smote = smt.fit_resample(X_train,y_train)\n",
    "    \n",
    "    # fit model on scaled training data:\n",
    "    model = my_pipeline.fit(X_train_smote, y_train_smote)\n",
    "    \n",
    "    # save the model to disk\n",
    "    filename = 'trained_model.sav'\n",
    "    #pickle.dump(my_pipeline, open(filename, 'wb'))\n",
    "    \n",
    "    return pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_rf_model = trainModel(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictCrop(array):\n",
    "    \n",
    "     \"\"\" This function loads model from disk and predicts\n",
    "     the probability of copy type.\n",
    "     input: array of the 13 Sentinel bands, QA10,20 and 60,\n",
    "     ndvi, and season.\"\"\"\n",
    "    \n",
    "    # load the model from disk\n",
    "    filename = 'trained_model.sav'\n",
    "    trained_model = pickle.load(open(filename, 'rb'))\n",
    "    \n",
    "    # Predict crop type\n",
    "    predicted_crop_type = trained_model.predict_proba([array])\n",
    "\n",
    "    return predicted_crop_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

# -*- coding: utf-8 -*-
"""download_folder_from_S3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZZQ8U2LNBBpVkQKyq3s7dLcT8SbeMG1Y
"""

# !pip install boto3 && pip install awscli
#
# !aws configure

import boto3
from pathlib import Path
import pprint

if ('omdena' in boto3.session.Session().available_profiles):
    profile = 'omdena'
    print(f"Using profile: {profile}")
else:
    profile = 'default'
    print(f"Using profile: {profile}")
#profile = 'default' # overwrite if you want to use other profiles
boto3.setup_default_session(profile_name=profile)

AWS_REGION = 'us-west-1'
BUCKET_NAME = 'omdena-gpsdd-senegal' # bucket_names may not include capital letters or underscores

data_folder = Path.cwd().parent.parent.joinpath('path_to_where_you_want_to_save_the_downloaded_folder')
data_folder

s3_client = boto3.client('s3', region_name=AWS_REGION)

# try to create the bucket, this will fail if the bucket name is not globally unique
try:
    response = s3_client.create_bucket(
        Bucket=BUCKET_NAME,
        ACL='public-read',
        CreateBucketConfiguration={'LocationConstraint': AWS_REGION})
    bucket_url = response['Location']
    print(f"Bucket URL: {bucket_url}") 
except:
    print("Could not create bucket")

def download_s3_folder(bucket_name, s3_folder, local_dir=None):
    """
    Download the contents of a folder directory
    Args:
        bucket_name: the name of the s3 bucket
        s3_folder: the folder path in the s3 bucket
        local_dir: a relative or absolute directory path in the local file system
    """
    s3_resource = boto3.resource('s3')
    bucket = s3_resource.Bucket(bucket_name)

    # extract folder structure 
    folders = []
    for obj in bucket.objects.filter(Prefix=s3_folder):
        obj_split = obj.key.split('/')
        if obj.key.endswith('/'): # do we still need this?
            # print(obj.keys) 
            folders.append(obj.key)
        elif (len(obj_split) > 1):
            subfolder = "/".join(obj_split[:-1])
            # print(subfolder)
            folders.append(subfolder)
        else:
            pass

    # create local folder structure if it doesn't exist
    folder_set = {*folders}
    print(set(folder_set))
    for folder in folder_set:
        new_path= local_dir.joinpath(folder)
        print(new_path)
        new_path.mkdir(mode=0o777, parents=True, exist_ok=True)
        
    
    # download the files into the corresponding directories
    for obj in bucket.objects.filter(Prefix=s3_folder):
        if obj.key.endswith('/'): # important, because code will break if we try to write to a folder instead of a file
            pass
        else:
            obj_split = obj.key.split('/')
            if (len(obj_split) > 1):
                #print(obj_split)
                file_name = obj_split[-1]
                print(f"Filename {file_name}")
                sub_folder = "/".join(obj_split[:-1])
                #sub_folder = sub_folder + "/"   ## does not solve the Win 5 error
                folder = local_dir.joinpath(sub_folder)
                file_path = folder.joinpath(file_name)
                print(f"File path {file_path}")
                #print(obj)
                if file_path.is_file():
                    print(f"File {file_path} already exists and will not be downloaded.")
                else:
                    print(f"Downloading file to {file_path}")
                    #bucket.download_file(obj.key, obj.key)
                    bucket.download_file(obj.key, str(file_path))
    return

s3_folder = "data/IPAR_data/IPAR_1500ha_maize_2014"
download_s3_folder(BUCKET_NAME, s3_folder, local_dir=data_folder)